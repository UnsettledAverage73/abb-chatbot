{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Analysis and Embeddings for ABB Chatbot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pandas openpyxl sentence-transformers\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "file1 = \"/home/unsettledaverage73/ABB-chatbot/abb-chatbot/3439_RMU_StockObso_2507A-1(1).csv\"\n",
        "file2 = \"/home/unsettledaverage73/ABB-chatbot/abb-chatbot/sustainbility2(1).csv\"\n",
        "\n",
        "print(f\"--- Analyzing {file1} ---\")\n",
        "try:\n",
        "    df1 = pd.read_excel(file1)\n",
        "    print(\"Head of the dataframe:\")\n",
        "    print(df1.head())\n",
        "    print(\"\\nColumns:\")\n",
        "    print(df1.columns)\n",
        "    print(\"\\nSummary statistics:\")\n",
        "    print(df1.describe())\n",
        "except Exception as e:\n",
        "    print(f\"Error reading {file1}: {e}\")\n",
        "\n",
        "print(f\"\\n--- Analyzing {file2} ---\")\n",
        "try:\n",
        "    df2 = pd.read_excel(file2)\n",
        "    print(\"Head of the dataframe:\")\n",
        "    print(df2.head())\n",
        "    print(\"\\nColumns:\")\n",
        "    print(df2.columns)\n",
        "    print(\"\\nSummary statistics:\")\n",
        "    print(df2.describe())\n",
        "except Exception as e:\n",
        "    print(f\"Error reading {file2}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Initialize the Sentence Transformer model\n",
        "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "# Prepare text for embeddings for df1 (3439_RMU_StockObso_2507A-1(1).csv)\n",
        "# Convert all relevant columns to string and join them\n",
        "if 'df1' in locals() and not df1.empty:\n",
        "    df1_text_columns = ['Manual', 'Jan 2025', 'Dec 2024']\n",
        "    df1['combined_text'] = df1[df1_text_columns].astype(str).agg(' '.join, axis=1)\n",
        "    df1['embeddings'] = list(model.encode(df1['combined_text'].tolist()))\n",
        "    print(f\"\\nEmbeddings generated for {file1}. Shape: {df1['embeddings'].shape}\")\n",
        "    print(\"First 5 embeddings for df1:\")\n",
        "    for i, embedding in enumerate(df1['embeddings'].head()):\n",
        "        print(f\"Row {i}: {embedding[:5]}...\") # print first 5 dimensions of embedding\n",
        "else:\n",
        "    print(f\"\\n{file1} is empty or not loaded, skipping embeddings.\")\n",
        "\n",
        "# Prepare text for embeddings for df2 (sustainbility2(1).csv)\n",
        "# Convert all relevant columns to string and join them\n",
        "if 'df2' in locals() and not df2.empty:\n",
        "    df2_text_columns = [\n",
        "        'Date', 'Plastic Reduced (kg)', 'Daily Plastic Consumption (kg)',\n",
        "        'Wood Consumption (kg)', 'Energy Consumption (kWh)', 'E-Waste (kg)',\n",
        "        'SF6 Consumption (kg)', 'Argon Consumption (kg)', 'Helium Consumption (kg)',\n",
        "        'CO2 Emission (kg)', 'Hazardous Waste (kg)'\n",
        "    ]\n",
        "    # Ensure all columns exist before trying to combine them\n",
        "    existing_df2_text_columns = [col for col in df2_text_columns if col in df2.columns]\n",
        "    if existing_df2_text_columns:\n",
        "        df2['combined_text'] = df2[existing_df2_text_columns].astype(str).agg(' '.join, axis=1)\n",
        "        df2['embeddings'] = list(model.encode(df2['combined_text'].tolist()))\n",
        "        print(f\"\\nEmbeddings generated for {file2}. Shape: {df2['embeddings'].shape}\")\n",
        "        print(\"First 5 embeddings for df2:\")\n",
        "        for i, embedding in enumerate(df2['embeddings'].head()):\n",
        "            print(f\"Row {i}: {embedding[:5]}...\") # print first 5 dimensions of embedding\n",
        "    else:\n",
        "        print(f\"\\nNo relevant text columns found in {file2}, skipping embeddings.\")\n",
        "else:\n",
        "    print(f\"\\n{file2} is empty or not loaded, skipping embeddings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "# Convert embeddings to a contiguous NumPy array with float32 type for FAISS\n",
        "if 'df2' in locals() and 'embeddings' in df2.columns and not df2['embeddings'].empty:\n",
        "    embeddings_array = np.array(df2['embeddings'].tolist()).astype('float32')\n",
        "\n",
        "    # Initialize a FAISS index\n",
        "    # Using IndexFlatL2 for a simple L2 distance (Euclidean distance) index\n",
        "    dimension = embeddings_array.shape[1]\n",
        "    index = faiss.IndexFlatL2(dimension)\n",
        "\n",
        "    # Add the embeddings to the index\n",
        "    index.add(embeddings_array)\n",
        "\n",
        "    print(f\"\\nFAISS index created with {index.ntotal} embeddings.\")\n",
        "\n",
        "    # Example: Query the vector store\n",
        "    query_text = \"What is the plastic consumption?\"\n",
        "    query_embedding = model.encode([query_text]).astype('float32')\n",
        "\n",
        "    D, I = index.search(query_embedding, k=3)  # Search for the 3 most similar embeddings\n",
        "\n",
        "    print(f\"\\nQuery: {query_text}\")\n",
        "    print(\"Most similar entries (FAISS scores and indices):\")\n",
        "    for i in range(len(I[0])):\n",
        "        print(f\"  Score: {D[0][i]:.4f}, Index: {I[0][i]}, Text: {df2.loc[I[0][i], 'combined_text']}\")\n",
        "else:\n",
        "    print(f\"\\nDataFrame df2 or its embeddings are not available, skipping FAISS index creation and query.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generation: Answering Questions with an LLM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Initialize a question-answering pipeline with an open-source LLM\n",
        "# We'll use distilbert-base-uncased-distilled-squad for better extractive QA performance\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-uncased-distilled-squad\")\n",
        "\n",
        "# Assuming 'query_text' and 'I' (indices of relevant documents) are available from the previous step\n",
        "# We'll re-define them here for standalone execution of this cell if needed.\n",
        "# In a full run, these would be passed from the previous cell's execution.\n",
        "if 'query_text' not in locals():\n",
        "    query_text = \"What is the plastic consumption?\"\n",
        "\n",
        "if 'I' in locals() and 'df2' in locals():\n",
        "    # Get the most relevant context from df2 based on the FAISS search results\n",
        "    # Concatenate the 'combined_text' from the top retrieved rows\n",
        "    retrieved_contexts = [df2.loc[idx, 'combined_text'] for idx in I[0]]\n",
        "    context = \" \".join(retrieved_contexts)\n",
        "\n",
        "    print(f\"\\nOriginal Question: {query_text}\")\n",
        "    print(f\"Retrieved Context (from relevant CSV rows):\\n{context[:500]}...\") # Print first 500 chars of context\n",
        "\n",
        "    # Use the LLM to generate an answer\n",
        "    # We instruct the model to only use the provided context\n",
        "    llm_response = qa_pipeline(question=query_text, context=context)\n",
        "\n",
        "    print(f\"\\nLLM Answer: {llm_response['answer']}\")\n",
        "    print(f\"Confidence Score: {llm_response['score']:.4f}\")\n",
        "else:\n",
        "    print(\"\\nPrevious steps for query and retrieval were not executed. Please run prior cells.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
